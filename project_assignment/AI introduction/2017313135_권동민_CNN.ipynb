{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6f9e477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ac570e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b5441b6b90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 100\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d350de93",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03c7332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3cf8f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNameList(path):\n",
    "    return os.listdir(path)\n",
    "\n",
    "def resizeImage(input_path, output_path):\n",
    "    \n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "        \n",
    "    nameList = getNameList(input_path)\n",
    "        \n",
    "    for dirIdx in range(len(nameList)):\n",
    "        dir_name = nameList[dirIdx]\n",
    "        out_dir = os.path.join(output_path, dir_name)\n",
    "        \n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "        \n",
    "        dir_path = os.path.join(input_path, dir_name)\n",
    "            \n",
    "        dir_images = os.listdir(dir_path)\n",
    "        num_images = len(dir_images)\n",
    "        print(\"idx : \" + str(dirIdx) + ', len : ' + str(num_images))\n",
    "            \n",
    "        for i,image in enumerate(dir_images):\n",
    "            with open(os.path.join(dir_path, image), 'r+b') as f:\n",
    "                with Image.open(f) as img:\n",
    "                    img = img.resize([256, 256], Image.ANTIALIAS)\n",
    "                    img.save(os.path.join(out_dir, image), img.format)\n",
    "    \n",
    "    return nameList\n",
    "\n",
    "def createMap(ylist):\n",
    "    index2name = {}\n",
    "    name2index = {}\n",
    "    for i in range(len(ylist)):\n",
    "        name = ylist[i]\n",
    "        index2name[i] = name\n",
    "        name2index[name] = i\n",
    "    \n",
    "    return index2name, name2index\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f26b51e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx : 0, len : 130\n",
      "idx : 1, len : 130\n",
      "idx : 2, len : 130\n",
      "idx : 3, len : 129\n",
      "idx : 4, len : 131\n",
      "idx : 5, len : 131\n",
      "idx : 6, len : 129\n",
      "idx : 7, len : 125\n",
      "idx : 8, len : 129\n",
      "idx : 9, len : 130\n",
      "idx : 10, len : 130\n",
      "idx : 11, len : 129\n",
      "idx : 12, len : 127\n",
      "idx : 13, len : 133\n",
      "idx : 14, len : 130\n",
      "idx : 15, len : 131\n",
      "idx : 16, len : 129\n",
      "idx : 17, len : 129\n",
      "idx : 18, len : 124\n",
      "idx : 19, len : 129\n",
      "idx : 20, len : 130\n",
      "idx : 21, len : 127\n",
      "idx : 22, len : 128\n",
      "idx : 23, len : 130\n",
      "idx : 24, len : 131\n"
     ]
    }
   ],
   "source": [
    "y_dataList = resizeImage(\"./Dog_breeds_Dataset\", \"./Dog_breeds_Dataset_resized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "345e0714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['African_hunting_dog', 'basenji', 'beagle', 'black-and-tan_coonhound', 'Blenheim_spaniel', 'Boston_bull', 'Chihuahua', 'clumber', 'dingo', 'EntleBucher', 'Japanese_spaniel', 'keeshond', 'komondor', 'Leonberg', 'Maltese_dog', 'Norwegian_elkhound', 'otterhound', 'Pomeranian', 'pug', 'Shih-Tzu', 'Siberian_husky', 'silky_terrier', 'standard_schnauzer', 'Welsh_springer_spaniel', 'Yorkshire_terrier']\n",
      "25\n",
      "\n",
      "\n",
      "black-and-tan_coonhound 22\n"
     ]
    }
   ],
   "source": [
    "index2name, name2index = createMap(y_dataList)\n",
    "print(y_dataList)\n",
    "print(len(y_dataList))\n",
    "print()\n",
    "print()\n",
    "print(index2name[3], name2index[\"standard_schnauzer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6eec67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDS(data.Dataset):\n",
    "    def __init__(self, yList, root, name2idx, transform=None):\n",
    "        self.yList = yList\n",
    "        self.root = root\n",
    "        self.x_data = []\n",
    "        self.y_data = []\n",
    "        self.transform = transform\n",
    "        self.name2idx = name2idx\n",
    "\n",
    "        for i in range(len(self.yList)):\n",
    "            path = os.path.join(root, self.yList[i])\n",
    "            \n",
    "            images = os.listdir(path)\n",
    "            for j in range(len(images)):\n",
    "                self.x_data.append(images[j])\n",
    "                self.y_data.append(self.yList[i])    \n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        target = self.y_data[index]\n",
    "        \n",
    "        image = Image.open(os.path.join(self.root, target, self.x_data[index])).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        target = self.name2idx[target]\n",
    "        \n",
    "        return image, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f78e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "totalDS = customDS(y_dataList, \"./Dog_breeds_Dataset_resized\", name2index, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd4e1ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3231\n"
     ]
    }
   ],
   "source": [
    "print(len(totalDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5f6b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeValRandom():\n",
    "    \n",
    "    idxList = list(range(len(totalDS)))\n",
    "    np.random.shuffle(idxList)\n",
    "\n",
    "    split = int(np.floor(0.7 * len(totalDS)))\n",
    "    trainIdx, validIdx = idxList[:split], idxList[split:]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(trainIdx)\n",
    "    valid_sampler = SubsetRandomSampler(validIdx)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        dataset=totalDS,\n",
    "        batch_size=50,\n",
    "        num_workers=0,\n",
    "        sampler=train_sampler\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        dataset=totalDS,\n",
    "        batch_size=50,\n",
    "        num_workers=0,\n",
    "        sampler=valid_sampler\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45051316",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = makeValRandom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be06d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            #224x224 -> \n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(128, 256, 3, stride=1, padding=1, bias=False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(256, 512, 3, stride=1, padding=1, bias=False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(512 * 14 * 14, 128)\n",
    "        self.fc2 = nn.Linear(128, 25)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x.view(-1, 3, 224, 224)\n",
    "        out = self.conv(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.dropout(F.relu(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0aed782",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9443b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : (1/50) tr_Loss: 160.59, val_Loss: 64.15 / tr_Acc: 4.5, Val_Acc: 6.7\n",
      "epoch : (2/50) tr_Loss: 146.67, val_Loss: 62.18 / tr_Acc: 7.2, Val_Acc: 9.1\n",
      "epoch : (3/50) tr_Loss: 141.52, val_Loss: 60.51 / tr_Acc: 9.8, Val_Acc: 11.0\n",
      "epoch : (4/50) tr_Loss: 135.68, val_Loss: 58.61 / tr_Acc: 13.4, Val_Acc: 14.8\n",
      "epoch : (5/50) tr_Loss: 131.10, val_Loss: 56.23 / tr_Acc: 16.5, Val_Acc: 17.6\n",
      "epoch : (6/50) tr_Loss: 125.30, val_Loss: 54.55 / tr_Acc: 19.0, Val_Acc: 21.3\n",
      "epoch : (7/50) tr_Loss: 120.36, val_Loss: 53.16 / tr_Acc: 22.0, Val_Acc: 20.5\n",
      "epoch : (8/50) tr_Loss: 118.11, val_Loss: 51.52 / tr_Acc: 23.6, Val_Acc: 22.9\n",
      "epoch : (9/50) tr_Loss: 112.78, val_Loss: 52.36 / tr_Acc: 27.2, Val_Acc: 23.6\n",
      "epoch : (10/50) tr_Loss: 110.29, val_Loss: 48.88 / tr_Acc: 27.9, Val_Acc: 29.8\n",
      "epoch : (11/50) tr_Loss: 103.42, val_Loss: 48.76 / tr_Acc: 32.7, Val_Acc: 27.0\n",
      "epoch : (12/50) tr_Loss: 101.22, val_Loss: 47.02 / tr_Acc: 34.1, Val_Acc: 29.3\n",
      "epoch : (13/50) tr_Loss: 97.65, val_Loss: 46.96 / tr_Acc: 35.8, Val_Acc: 29.8\n",
      "epoch : (14/50) tr_Loss: 92.37, val_Loss: 46.12 / tr_Acc: 39.1, Val_Acc: 32.7\n",
      "epoch : (15/50) tr_Loss: 89.27, val_Loss: 47.57 / tr_Acc: 40.7, Val_Acc: 32.5\n",
      "epoch : (16/50) tr_Loss: 85.76, val_Loss: 47.51 / tr_Acc: 43.3, Val_Acc: 30.7\n",
      "epoch : (17/50) tr_Loss: 83.51, val_Loss: 45.13 / tr_Acc: 44.5, Val_Acc: 32.0\n",
      "epoch : (18/50) tr_Loss: 79.26, val_Loss: 45.19 / tr_Acc: 45.9, Val_Acc: 36.0\n",
      "epoch : (19/50) tr_Loss: 76.14, val_Loss: 45.02 / tr_Acc: 49.6, Val_Acc: 35.4\n",
      "epoch : (20/50) tr_Loss: 72.86, val_Loss: 42.04 / tr_Acc: 51.3, Val_Acc: 38.8\n",
      "epoch : (21/50) tr_Loss: 68.02, val_Loss: 43.11 / tr_Acc: 52.8, Val_Acc: 37.9\n",
      "epoch : (22/50) tr_Loss: 66.83, val_Loss: 42.69 / tr_Acc: 55.4, Val_Acc: 39.6\n",
      "epoch : (23/50) tr_Loss: 66.71, val_Loss: 44.14 / tr_Acc: 55.9, Val_Acc: 36.5\n",
      "epoch : (24/50) tr_Loss: 63.26, val_Loss: 45.12 / tr_Acc: 57.9, Val_Acc: 39.3\n",
      "epoch : (25/50) tr_Loss: 57.62, val_Loss: 46.70 / tr_Acc: 61.7, Val_Acc: 35.5\n",
      "epoch : (26/50) tr_Loss: 58.88, val_Loss: 46.21 / tr_Acc: 60.6, Val_Acc: 36.6\n",
      "epoch : (27/50) tr_Loss: 56.77, val_Loss: 45.18 / tr_Acc: 61.8, Val_Acc: 39.1\n",
      "epoch : (28/50) tr_Loss: 53.78, val_Loss: 43.41 / tr_Acc: 63.6, Val_Acc: 39.8\n",
      "epoch : (29/50) tr_Loss: 50.52, val_Loss: 45.82 / tr_Acc: 65.5, Val_Acc: 39.5\n",
      "epoch : (30/50) tr_Loss: 48.41, val_Loss: 47.71 / tr_Acc: 65.9, Val_Acc: 38.0\n",
      "epoch : (31/50) tr_Loss: 50.03, val_Loss: 45.90 / tr_Acc: 67.5, Val_Acc: 41.8\n",
      "epoch : (32/50) tr_Loss: 47.38, val_Loss: 46.65 / tr_Acc: 68.3, Val_Acc: 41.0\n",
      "epoch : (33/50) tr_Loss: 41.46, val_Loss: 49.63 / tr_Acc: 71.8, Val_Acc: 39.3\n",
      "epoch : (34/50) tr_Loss: 44.27, val_Loss: 48.11 / tr_Acc: 70.3, Val_Acc: 40.7\n",
      "epoch : (35/50) tr_Loss: 43.00, val_Loss: 48.75 / tr_Acc: 69.7, Val_Acc: 41.1\n",
      "epoch : (36/50) tr_Loss: 43.64, val_Loss: 47.76 / tr_Acc: 69.7, Val_Acc: 41.1\n",
      "epoch : (37/50) tr_Loss: 41.52, val_Loss: 49.32 / tr_Acc: 70.3, Val_Acc: 41.0\n",
      "epoch : (38/50) tr_Loss: 38.24, val_Loss: 48.23 / tr_Acc: 74.4, Val_Acc: 42.1\n",
      "epoch : (39/50) tr_Loss: 33.83, val_Loss: 49.17 / tr_Acc: 75.7, Val_Acc: 43.1\n",
      "epoch : (40/50) tr_Loss: 34.76, val_Loss: 51.91 / tr_Acc: 76.1, Val_Acc: 41.8\n",
      "epoch : (41/50) tr_Loss: 34.86, val_Loss: 51.46 / tr_Acc: 76.6, Val_Acc: 41.6\n",
      "epoch : (42/50) tr_Loss: 33.84, val_Loss: 49.39 / tr_Acc: 77.5, Val_Acc: 40.0\n",
      "epoch : (43/50) tr_Loss: 32.23, val_Loss: 49.99 / tr_Acc: 77.6, Val_Acc: 42.3\n",
      "epoch : (44/50) tr_Loss: 31.91, val_Loss: 48.71 / tr_Acc: 78.2, Val_Acc: 41.6\n",
      "epoch : (45/50) tr_Loss: 32.68, val_Loss: 52.28 / tr_Acc: 77.9, Val_Acc: 40.8\n",
      "epoch : (46/50) tr_Loss: 29.50, val_Loss: 55.49 / tr_Acc: 79.7, Val_Acc: 43.7\n",
      "epoch : (47/50) tr_Loss: 30.78, val_Loss: 51.17 / tr_Acc: 78.3, Val_Acc: 44.0\n",
      "epoch : (48/50) tr_Loss: 30.32, val_Loss: 53.46 / tr_Acc: 79.9, Val_Acc: 41.9\n",
      "epoch : (49/50) tr_Loss: 28.29, val_Loss: 54.16 / tr_Acc: 80.4, Val_Acc: 41.5\n",
      "epoch : (50/50) tr_Loss: 29.53, val_Loss: 55.44 / tr_Acc: 79.6, Val_Acc: 41.8\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "#train_loader, val_loader = makeValRandom()\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "    trn_loss = 0\n",
    "    trn_total = 0\n",
    "    trn_correct = 0\n",
    "    \n",
    "    model.train()\n",
    "    for img, label in train_loader:\n",
    "        \n",
    "        img, label = img.to(device), label.to(device)\n",
    "        \n",
    "        hypothesis = model(img)\n",
    "        loss = criterion(hypothesis, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        trn_loss += loss.item()\n",
    "        \n",
    "        _, predicted = hypothesis.max(1)\n",
    "        trn_total += label.size(0)\n",
    "        trn_correct += predicted.eq(label).sum().item()\n",
    "    trn_acc = trn_correct / trn_total\n",
    "    \n",
    "    val_loss = 0\n",
    "    val_total = 0\n",
    "    val_correct = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for img, label in val_loader:\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            \n",
    "            results = model(img)\n",
    "            loss = criterion(results, label)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = results.max(1)\n",
    "            val_total += label.size(0)\n",
    "            val_correct += predicted.eq(label).sum().item()\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        writer.add_scalar('Loss/train_loss', trn_loss, epoch)\n",
    "        writer.add_scalar('Loss/valid_loss', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/train_accuracy', trn_acc * 100, epoch)\n",
    "        writer.add_scalar('Accuracy/valid_accuracy', val_acc * 100, epoch)\n",
    "        \n",
    "        print('epoch : (%d/%d) tr_Loss: %.2f, val_Loss: %.2f / tr_Acc: %.1f, Val_Acc: %.1f'\n",
    "                 %(epoch, epochs, trn_loss, val_loss, trn_acc*100, val_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93e71948",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549d4f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d908a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df1ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a274da6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244edbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd6ee1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c9902e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bec9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce0644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d3c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a229ebb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710cb4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
